{"cells":[{"cell_type":"code","source":["# ingestion to Bronze\n# read in payments.csv\ndf = spark.read.format('csv') \\\n            .option('inferSchema', 'true') \\\n            .option('header', 'false') \\\n            .option('sep', ',') \\\n            .load('/FileStore/project2/payments.csv') \\\n            .toDF('payment_id', 'date', 'amount', 'rider_id')\n\ndf = df.withColumn(\"date\", df[\"date\"].cast('date')) \\\n        .withColumn(\"amount\", df[\"amount\"].cast('float'))\ndf.printSchema()\n\n# write payments to delta\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .save('/delta/bronze_payments')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4594a14d-d270-416c-8630-77b30bdc3087"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- payment_id: integer (nullable = true)\n |-- date: date (nullable = true)\n |-- amount: float (nullable = true)\n |-- rider_id: integer (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- payment_id: integer (nullable = true)\n-- date: date (nullable = true)\n-- amount: float (nullable = true)\n-- rider_id: integer (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# read payments from delta\ndf = spark.read.format('delta') \\\n        .load('/delta/bronze_payments')\n\n# convert payments to table\nspark.sql(\"DROP TABLE IF EXISTS bronze_dimPayment\")\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .saveAsTable('bronze_dimPayment')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"deae0b6a-bbce-400f-815f-9b28f2d80f9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# ingestion to Bronze\n# read in riders.csv\ndf = spark.read.format('csv') \\\n            .option('inferSchema', 'true') \\\n            .option('header', 'false') \\\n            .option('sep', ',') \\\n            .load('/FileStore/project2/riders.csv') \\\n            .toDF('rider_id', 'first', 'last', 'address', 'birthday', 'account_start_date', 'account_end_date', 'is_member')\n\ndf = df.withColumn(\"birthday\", df[\"birthday\"].cast('date')) \\\n        .withColumn(\"account_start_date\", df[\"account_start_date\"].cast('date')) \\\n        .withColumn(\"account_end_date\", df[\"account_end_date\"].cast('date'))\ndf.printSchema()\n\n# write riders to delta\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .save('/delta/bronze_riders')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62886989-50c6-4262-8c96-ce70d4e68f9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- rider_id: integer (nullable = true)\n |-- first: string (nullable = true)\n |-- last: string (nullable = true)\n |-- address: string (nullable = true)\n |-- birthday: date (nullable = true)\n |-- account_start_date: date (nullable = true)\n |-- account_end_date: date (nullable = true)\n |-- is_member: boolean (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- rider_id: integer (nullable = true)\n-- first: string (nullable = true)\n-- last: string (nullable = true)\n-- address: string (nullable = true)\n-- birthday: date (nullable = true)\n-- account_start_date: date (nullable = true)\n-- account_end_date: date (nullable = true)\n-- is_member: boolean (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# read riders from delta\ndf = spark.read.format('delta') \\\n        .load('/delta/bronze_riders')\n\n# convert riders to table\nspark.sql(\"DROP TABLE IF EXISTS gold_dimRider\")\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .saveAsTable('gold_dimRider')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc30a663-0060-45fe-9652-2185278ffad7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# ingestion to Bronze\n# read in trips.csv\ndf = spark.read.format('csv') \\\n            .option('inferSchema', 'true') \\\n            .option('header', 'false') \\\n            .option('sep', ',') \\\n            .load('/FileStore/project2/trips.csv') \\\n            .toDF('trip_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_id', 'end_station_id', 'rider_id')\n\ndf.printSchema()\n\n# write trips to delta\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .save('/delta/bronze_trips')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14bc5f26-eae5-4066-9d26-175311896732"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- trip_id: string (nullable = true)\n |-- rideable_type: string (nullable = true)\n |-- started_at: timestamp (nullable = true)\n |-- ended_at: timestamp (nullable = true)\n |-- start_station_id: string (nullable = true)\n |-- end_station_id: string (nullable = true)\n |-- rider_id: integer (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- trip_id: string (nullable = true)\n-- rideable_type: string (nullable = true)\n-- started_at: timestamp (nullable = true)\n-- ended_at: timestamp (nullable = true)\n-- start_station_id: string (nullable = true)\n-- end_station_id: string (nullable = true)\n-- rider_id: integer (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# read trips from delta\ndf = spark.read.format('delta') \\\n        .load('/delta/bronze_trips')\n\n# convert trips to table\nspark.sql(\"DROP TABLE IF EXISTS bronze_dimTrip\")\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .saveAsTable('bronze_dimTrip')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3eadb577-8f75-4bad-9bba-a649fb8f846f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# ingestion to Bronze\n# read in stations.csv\ndf = spark.read.format('csv') \\\n            .option('inferSchema', 'true') \\\n            .option('header', 'false') \\\n            .option('sep', ',') \\\n            .load('/FileStore/project2/stations.csv') \\\n            .toDF('station_id', 'name', 'latitude', 'longitude')\n\ndf.printSchema()\n\n# write riders to delta\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .save('/delta/bronze_stations')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c84a6f8e-7b18-4c00-96e2-0251ac8271a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- station_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- station_id: string (nullable = true)\n-- name: string (nullable = true)\n-- latitude: double (nullable = true)\n-- longitude: double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# read stations from delta\ndf = spark.read.format('delta') \\\n        .load('/delta/bronze_stations')\n\n# convert station to tables\nspark.sql(\"DROP TABLE IF EXISTS gold_dimStation\")\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .saveAsTable('gold_dimStation')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97903188-b846-4a2b-b2d9-dafcb191b874"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Derivative of https://sparkbyexamples.com/pyspark/pyspark-sql-date-and-timestamp-functions/\n# Gold business level\n# create Date calendar dimension table\nfrom pyspark.sql.functions import *\n\nstart,stop = ['2013-01-01', '2043-01-01']\ninterval=60*60*24\ndt_col=\"date_time\"\n\ntemp_df = spark.createDataFrame([(start, stop)], (\"start\", \"stop\"))\ntemp_df = temp_df.select([col(c).cast(\"timestamp\") for c in (\"start\", \"stop\")])\ntemp_df = temp_df.withColumn(\"stop\",F.date_add(\"stop\",1).cast(\"timestamp\"))\ntemp_df = temp_df.select([col(c).cast(\"long\") for c in (\"start\", \"stop\")])\nstart, stop = temp_df.first()\ndf = spark.range(start,stop,interval).select(col(\"id\").cast(\"timestamp\").alias(dt_col))\n\ndf = df.select(to_date(col(\"date_time\"), \"yyyy-MM-dd\").cast(StringType()).alias(\"date_id\"),\n     to_date(col(\"date_time\"), \"yyyy-MM-dd\").alias(\"date\"),\n     year(col(\"date_time\")).alias(\"year\"), \n     month(col(\"date_time\")).alias(\"month\"), \n     weekofyear(col(\"date_time\")).alias(\"weekofyear\") ,\n     dayofweek(col(\"date_time\")).alias(\"dayofweek\"), \n     dayofmonth(col(\"date_time\")).alias(\"dayofmonth\"), \n     dayofyear(col(\"date_time\")).alias(\"dayofyear\") \n  )\n\nspark.sql(\"DROP TABLE IF EXISTS gold_dimTime\")\ndf.write.format('delta') \\\n        .mode('overwrite') \\\n        .saveAsTable('gold_dimTime')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47fe4281-c630-4fe8-a548-bfaf0f16d14a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create factPayment fact table\nspark.sql(\"DROP TABLE IF EXISTS factPayment\")\nspark.sql(\"CREATE TABLE factPayment ( \\\n           date_key STRING, \\\n           rider_key INT, \\\n           amount DOUBLE) \\\n          \")\n\nspark.sql(\"INSERT INTO factPayment (date_key, rider_key, amount) \\\n            SELECT d.date_id            AS date_key, \\\n                   r.rider_id           AS rider_key, \\\n                   p.amount             AS amount \\\n            FROM bronze_dimPayment p \\\n            JOIN gold_dimRider r  ON (p.rider_id = r.rider_id) \\\n            JOIN gold_dimTime d ON (d.date = p.date) \\\n         \")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e377611-2dfb-4d85-99a9-1775d2a7ce4c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[210]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[210]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create factTrip fact table\nspark.sql(\"DROP TABLE IF EXISTS factTrip\")\nspark.sql(\"CREATE TABLE factTrip ( \\\n          date_key STRING, \\\n          rider_key INT, \\\n          start_station_key STRING, \\\n          end_station_key STRING, \\\n          rider_age INT, \\\n          trip_duration INT) \\\n          \")\n\nspark.sql(\"INSERT INTO factTrip (date_key, rider_key, start_station_key, end_station_key, rider_age, trip_duration) \\\n           SELECT d.date_id                                                                                                AS date_key, \\\n           r.rider_id                                                                                                      AS rider_key, \\\n           t.start_station_id                                                                                              AS start_station_key, \\\n           t.end_station_id                                                                                                AS end_station_key, \\\n           DATEDIFF(YEAR, r.birthday, t.started_at)                                  AS rider_age, \\\n           DATEDIFF(MINUTE, t.started_at, t.ended_at)  AS trip_duration \\\n           FROM bronze_dimTrip t \\\n           JOIN gold_dimRider r  ON (r.rider_id = t.rider_id) \\\n           JOIN bronze_dimPayment p  ON (p.rider_id = t.rider_id) \\\n           JOIN gold_dimTime d ON (d.date = p.date) \\\n         \")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f84418f6-242b-4a6b-a0b9-d9523779e060"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[211]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[211]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# remove delta files\n# dbutils.fs.rm('/delta/bronze_payments', recurse=True)\n# dbutils.fs.rm('/delta/bronze_riders', recurse=True)\n# dbutils.fs.rm('/delta/bronze_stations', recurse=True)\n# dbutils.fs.rm('/delta/bronze_trips', recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae651c74-2765-4247-9d9c-9e9b16d8c94b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"project2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2327524788650377}},"nbformat":4,"nbformat_minor":0}
