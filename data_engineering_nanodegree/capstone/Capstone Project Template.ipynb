{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# U.S. Visitors and Immigration Data Exploration \n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "##### To faciliate data analysis on the visitors and immigrants into the U.S., an ETL pipeline was created to extract I94 immigration data on arrivals to the U.S. and U.S. city temperatures and demographics from various open source datasets into stagging tables for transformation into dimensional and fact tables. Current and retrospective visitor and immigration patterns and distributions can be evaluated. Examples include:\n",
    "* Statistics and distribution of visa types to the U.S. (business, pleasure, student) and transport mode (air, land, or sea).\n",
    "* Median age and gender distribution of arrivals.\n",
    "* Relationship between popularity of arrival cities and their temperature at arrival date.\n",
    "* How the above distributions change over the seasons/months for each year and also over the years.\n",
    "\n",
    "#### The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here.\n",
    "import os\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import math\n",
    "from pyspark.sql.functions import count, isnull, isnan, col, year, month, round, udf, sum, dayofmonth, dayofweek, month, year, weekofyear\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import StringType, StructType, StructField, IntegerType\n",
    "\n",
    "\n",
    "# https://knowledge.udacity.com/questions/572487\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "\n",
    "# Config file containing AWS credentials.\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "# output path for data model parquet files.\n",
    "output_data = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    Creates a Spark session.\n",
    "    \"\"\"\n",
    "    from pyspark.sql import SparkSession\n",
    "#     spark = SparkSession.builder \\\n",
    "#     .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "#     .enableHiveSupport().getOrCreate()\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def code_mapper(f_content, idx, isnumeric=True):\n",
    "    \"\"\"\n",
    "    Reading of I94_SAS_Labels_Descriptions.SAS to get the country codes, city codes, transport modes, state codes, and visa codes.\n",
    "    Based on https://knowledge.udacity.com/questions/125439\n",
    "    \"\"\"\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    if isnumeric:\n",
    "        dic = dict([int(i[0].strip()), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    else:\n",
    "        dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "        \n",
    "    country_code_dict = code_mapper(f_content, \"i94cntyl\", isnumeric=True)\n",
    "    city_code_dict = code_mapper(f_content, \"i94prtl\", isnumeric=False)\n",
    "    transport_mode_dict = code_mapper(f_content, \"i94model\", isnumeric=True)\n",
    "    state_code_dict = code_mapper(f_content, \"i94addrl\", isnumeric=False)\n",
    "    visa_class_dict = {\n",
    "        1:'Business',\n",
    "        2: 'Pleasure',\n",
    "        3: 'Student'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Steps include:\n",
    "1. Load all datasets listed below into PySpark dataframes.\n",
    "2. Exploratory analysis of each of the datasets, eliminating any neccessary missing data, performing any data transformations, selecting only pertinent data, and any other data cleaning procedures.\n",
    "3. Design data models - staging, dimensional and fact tables for efficient SQL queries.\n",
    "4. Create the dimensional and fact tables.\n",
    "5. Design and perform quality checks on each of the tables.\n",
    "6. Perform tests and checks to ensure functionality and data accuracy.\n",
    "\n",
    "Spark and AWS are used.\n",
    "\n",
    "#### Describe and Gather Data\n",
    "1. I94 Immigration Data: Data comes from the US National Tourism and Trade Office (https://www.trade.gov/national-travel-and-tourism-office) and contains visitor and immigrant arrival information to the U.S.\n",
    "2. World Temperature Data: Data comes from Kaggle (https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) and contains average temperatures of cities around the world.\n",
    "3. U.S. City Demographic Data: Data comes from OpenSoft (https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/), and contains demographics of cities within the U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.1 I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read I94 immigration data.\n",
    "# Based on https://stackoverflow.com/questions/51949414/read-sas-sas7bdat-data-with-spark.\n",
    "# Note: Unable to read SAS from Spark with Udacity workspace, had error \"Exception: Java gateway process exited before sending its port number\"\n",
    "# Restorted to reading parquet data in sas_data\n",
    "# i94_filename = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "# i94_df = spark.read.format(\"com.github.saurfang.sas.spark\").load(i94_filename)\n",
    "i94_df = spark.read.load('./sas_data')\n",
    "i94_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary of I94 immigration data according to I94_SAS_Labels_Description.SAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "cicid|Unique record ID\n",
    "i94yr|4 digit year\n",
    "i94mon|Numeric month\n",
    "i94cit|3 digit code for immigrant country of birth\n",
    "i94res|3 digit code for immigrant country of residence\n",
    "i94port|Port of admission\n",
    "arrdate|Arrival Date in the USA\n",
    "i94mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "i94addr|USA State of arrival\n",
    "depdate|Departure Date from the USA\n",
    "i94bir|Age of Respondent in Years\n",
    "i94visa|Visa codes collapsed into three categories\n",
    "count|Field used for summary statistics\n",
    "dtadfile|Character Date Field - Date added to I-94 Files\n",
    "visapost|Department of State where where Visa was issued\n",
    "occup|Occupation that will be performed in U.S\n",
    "entdepa|Arrival Flag - admitted or paroled into the U.S.\n",
    "entdepd|\"Departure Flag - Departed\n",
    "entdepu|\"Update Flag - Either apprehended\n",
    "matflag|Match flag - Match of arrival and departure records\n",
    "biryear|4 digit year of birth\n",
    "dtaddto|Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "gender|Non-immigrant sex\n",
    "insnum|INS number\n",
    "airline|Airline used to arrive in U.S.\n",
    "admnum|Admission Number\n",
    "fltno|Flight number of Airline used to arrive in U.S.\n",
    "visatype|Code of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2. World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read temperature data.\n",
    "temperature_filename = \"../../data2/GlobalLandTemperaturesByCity.csv\"\n",
    "temperature_df = spark.read.csv(temperature_filename, header=True, sep=',', inferSchema=True)\n",
    "\n",
    "# Print out the top 5 rows\n",
    "temperature_df.show(5)\n",
    "\n",
    "# Print out schema and datatypes.\n",
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary of world temperature data according to https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "dt|Date\n",
    "AverageTemperature|Global average land temperature in celsius\n",
    "AverageTemperatureUncertainty|The 95% confidence interval around the average\n",
    "City|City Name\n",
    "Country|Country Name\n",
    "Latitude|City Latitude\n",
    "Longitude|City Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.3. U.S. Cities Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read demographics data.\n",
    "demographics_filename = \"us-cities-demographics.csv\"\n",
    "demographics_df = spark.read.csv(demographics_filename, header=True, sep=';', inferSchema=True)\n",
    "\n",
    "# Print out the top 5 rows.\n",
    "demographics_df.show(5)\n",
    "\n",
    "# Print out schema and datatypes.\n",
    "demographics_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary of U.S. cities demographics data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "City|City Name\n",
    "State|State\n",
    "Median Age|Median age\n",
    "Male Population|Total male population\n",
    "Female Population|Total female population\n",
    "Total Population|Total population\n",
    "Number of Veterans|Total veterans\n",
    "Foreign born|Total foreign born residents\n",
    "Average Household Size|Average number of people in household\n",
    "State Code|State code\n",
    "Race|Race\n",
    "Count|Total population identifying with race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data and Perform Cleaning and Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_missing_values(spark_df):\n",
    "    \"\"\"\n",
    "    Count number of missing values in each column\n",
    "    \"\"\"\n",
    "    df = spark_df.toPandas()\n",
    "    for column in df:\n",
    "        print(column, df[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def to_PySpark_date(date):\n",
    "    \"\"\"\n",
    "    udf to convert to PySpark date\n",
    "    Based on https://stackoverflow.com/questions/26923564/convert-sas-numeric-to-python-datetime.\n",
    "    \"\"\"\n",
    "    py_date = None\n",
    "    if date:\n",
    "        epoch = datetime(1960, 1, 1)\n",
    "        py_date = (epoch + timedelta(date)).isoformat()\n",
    "    return py_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def city_name_to_code(city):\n",
    "    \"\"\"\n",
    "    udf to find city_code from city name\n",
    "    \"\"\"\n",
    "    city_code = None\n",
    "    for key, value in city_code_dict.items():\n",
    "        list_city_splits = value.split(\", \")\n",
    "        if len(list_city_splits) > 1:\n",
    "            city_name = list_city_splits[0].lower()            \n",
    "        else:\n",
    "            city_name = value.lower()\n",
    "        if city_name == city.lower():\n",
    "            city_code = key\n",
    "    return city_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def country_name_to_code(country):\n",
    "    \"\"\"\n",
    "    udf to find country_code from country name\n",
    "    \"\"\"\n",
    "    country_code = None\n",
    "    for key, value in country_code_dict.items():\n",
    "        if country.lower() == value.lower():\n",
    "            country_code = key\n",
    "    return country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def code_to_country_name(code):\n",
    "    \"\"\"\n",
    "    udf to find country name from code\n",
    "    \"\"\"\n",
    "    return country_code_dict.get(int(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def code_to_city_name(code):\n",
    "    \"\"\"\n",
    "    udf to find city name from code\n",
    "    \"\"\"\n",
    "    city_name = city_code_dict.get(code)\n",
    "    if city_name:\n",
    "        city_name = city_name.split(\", \")[0]\n",
    "    return city_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning, Data Transformation and Selection Steps\n",
    "##### 2.1. I94 Visitor and Immigrant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n",
      "2943669\n",
      "+------------+-------------------+---------+-------------+----------+---+------+------------------+------------------+----------------------+----------------------+--------------+----------+---------+\n",
      "|immigrant_id|       arrival_date|city_code|    city_name|state_code|age|gender|country_code_birth|country_name_birth|country_code_residence|country_name_residence|transport_mode|visa_class|visa_code|\n",
      "+------------+-------------------+---------+-------------+----------+---+------+------------------+------------------+----------------------+----------------------+--------------+----------+---------+\n",
      "|          27|2016-04-01T00:00:00|      BOS|       BOSTON|        MA| 58|     M|               101|           ALBANIA|                   101|               ALBANIA|             1|         1|       B1|\n",
      "|     1775608|2016-04-10T00:00:00|      LOS|  LOS ANGELES|        CA| 62|     F|               101|           ALBANIA|                   101|               ALBANIA|             1|         2|       B2|\n",
      "|     1973039|2016-04-11T00:00:00|      NYC|     NEW YORK|        NY| 66|  null|               101|           ALBANIA|                   101|               ALBANIA|             1|         2|       B2|\n",
      "|     4250395|2016-04-23T00:00:00|      WAS|WASHINGTON DC|        VA| 15|     F|               101|           ALBANIA|                   101|               ALBANIA|             1|         2|       B2|\n",
      "|     5201203|2016-04-28T00:00:00|      FMY|   FORT MYERS|        NY| 44|  null|               101|           ALBANIA|                   101|               ALBANIA|             1|         2|       B2|\n",
      "+------------+-------------------+---------+-------------+----------+---+------+------------------+------------------+----------------------+----------------------+--------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- immigrant_id: integer (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- country_code_birth: integer (nullable = true)\n",
      " |-- country_name_birth: string (nullable = true)\n",
      " |-- country_code_residence: integer (nullable = true)\n",
      " |-- country_name_residence: string (nullable = true)\n",
      " |-- transport_mode: integer (nullable = true)\n",
      " |-- visa_class: integer (nullable = true)\n",
      " |-- visa_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial number of rows.\n",
    "print(i94_df.count())\n",
    "\n",
    "# Drop NaN in select columns.\n",
    "staging_i94_df = i94_df.dropna(how=\"any\", subset=[\"cicid\", \"i94addr\", \"arrdate\", \"i94cit\", \"i94res\", \"i94port\"])\n",
    "\n",
    "# Drop any non-US states.\n",
    "staging_i94_df = staging_i94_df.filter(i94_df['i94addr'] != \"99\")\n",
    "\n",
    "# Convert SAS arrdata to PySpark data, country code to country name, city code to city name\n",
    "# Cast cicid, i94bir, i94cit, i94res, i94mode, i94visa from double to int\n",
    "staging_i94_df = staging_i94_df.withColumn(\"arrival_date\", to_PySpark_date(staging_i94_df['arrdate'])) \\\n",
    "    .withColumn(\"country_name_birth\", code_to_country_name(staging_i94_df['i94cit'])) \\\n",
    "    .withColumn(\"country_name_residence\", code_to_country_name(staging_i94_df['i94res'])) \\\n",
    "    .withColumn(\"city_name\", code_to_city_name(staging_i94_df['i94port'])) \\\n",
    "    .withColumn(\"cicid\", col(\"cicid\").cast(\"int\")) \\\n",
    "    .withColumn(\"i94bir\", col(\"i94bir\").cast(\"int\")) \\\n",
    "    .withColumn(\"i94cit\", col(\"i94cit\").cast(\"int\")) \\\n",
    "    .withColumn(\"i94res\", col(\"i94res\").cast(\"int\")) \\\n",
    "    .withColumn(\"i94mode\", col(\"i94mode\").cast(\"int\")) \\\n",
    "    .withColumn(\"i94visa\", col(\"i94visa\").cast(\"int\"))\n",
    "\n",
    "# Select specific columns.\n",
    "staging_i94_df = staging_i94_df.select(col(\"cicid\").alias(\"immigrant_id\"), \n",
    "                                       col(\"arrival_date\"),\n",
    "                                       col(\"i94port\").alias(\"city_code\"),\n",
    "                                       col(\"city_name\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\"),\n",
    "                                       col(\"i94cit\").alias(\"country_code_birth\"),\n",
    "                                       col(\"country_name_birth\"),\n",
    "                                       col(\"i94res\").alias(\"country_code_residence\"),\n",
    "                                       col(\"country_name_residence\"),\n",
    "                                       col(\"i94mode\").alias(\"transport_mode\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_class\"),\n",
    "                                       col(\"visatype\").alias(\"visa_code\")\n",
    "                                      ).drop_duplicates()\n",
    "\n",
    "# Final number of rows and schema.\n",
    "print(staging_i94_df.count())\n",
    "staging_i94_df.show(5)\n",
    "staging_i94_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2. Cities Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599212\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|year|month|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
      "|2013-01-01 00:00:00|              6.32|                        0.267|Abilene|United States|  32.95N|  100.53W|2013|    1|\n",
      "|2013-06-01 00:00:00|            27.831|          0.24600000000000002|Abilene|United States|  32.95N|  100.53W|2013|    6|\n",
      "|2013-02-01 00:00:00|             8.116|                        0.222|Abilene|United States|  32.95N|  100.53W|2013|    2|\n",
      "|2013-03-01 00:00:00|            12.503|                        0.273|Abilene|United States|  32.95N|  100.53W|2013|    3|\n",
      "|2013-04-01 00:00:00|15.752999999999998|                        0.342|Abilene|United States|  32.95N|  100.53W|2013|    4|\n",
      "+-------------------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "2312\n",
      "+----+-----+---------+-----------+-------------------+\n",
      "|year|month|city_code|  city_name|average_temperature|\n",
      "+----+-----+---------+-----------+-------------------+\n",
      "|2013|    1|     null|Clarksville|                4.8|\n",
      "|2013|    8|     null|     Dayton|               22.4|\n",
      "|2013|    3|     null|     Durham|                6.6|\n",
      "|2013|    7|     null|     Edison|               24.7|\n",
      "|2013|    3|     null| Fort Wayne|                0.6|\n",
      "+----+-----+---------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- average_temperature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial total count before cleaning.\n",
    "print(temperature_df.count())\n",
    "\n",
    "# Isolate just U.S. cities, convert dt to datetime.\n",
    "staging_temperature_df = temperature_df.filter(temperature_df['Country'] == \"United States\") \\\n",
    "    .withColumn(\"year\", year(temperature_df['dt'])) \\\n",
    "    .withColumn(\"month\", month(temperature_df['dt']))\n",
    "    \n",
    "# Isolate just the latest year, convert city name to city code.\n",
    "print(staging_temperature_df.orderBy('year', ascending=False).show(5))\n",
    "staging_temperature_df = staging_temperature_df.filter(staging_temperature_df['year'] == \"2013\") \\\n",
    "    .withColumn(\"city_code\", city_name_to_code(staging_temperature_df['City']))\n",
    "\n",
    "# Drop NaN for select columns.\n",
    "staging_temperature_df = staging_temperature_df.dropna(how=\"any\", subset=[\"dt\", \"City\", \"AverageTemperature\"])\n",
    "\n",
    "# Select specific columns.\n",
    "staging_temperature_df = staging_temperature_df.select(col(\"year\"), \n",
    "                                                       col(\"month\"),\n",
    "                                                       col(\"city_code\"),\n",
    "                                                       col(\"City\").alias(\"city_name\"),\n",
    "                                                       round(col(\"AverageTemperature\"), 1).alias(\"average_temperature\")\n",
    "                                                      ).drop_duplicates()\n",
    "\n",
    "# Final number of rows and schema.\n",
    "print(staging_temperature_df.count())\n",
    "staging_temperature_df.show(5)\n",
    "staging_temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.3. Cities Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n",
      "596\n",
      "+---------+------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "|city_code|   city_name|state_code|median_age|percent_male|percent_female|percent_veterans|percent_foreign_born|percent_native|percent_asian|percent_black|percent_hispanic|percent_white|total_population|\n",
      "+---------+------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "|     null|     Modesto|        CA|      35.2|        49.6|          50.4|             4.7|                18.8|           2.1|          9.2|          4.7|            40.3|         78.9|          211257|\n",
      "|     null|  Pittsburgh|        PA|      32.9|        49.2|          50.8|             5.8|                 9.3|           0.9|          7.0|         27.0|             3.0|         68.6|          304385|\n",
      "|     null|South Jordan|        UT|      33.8|        50.5|          49.5|             3.9|                 9.2|          null|          3.7|         null|             7.0|         88.6|           66639|\n",
      "|     null|     Passaic|        NJ|      30.4|        51.4|          48.6|             1.0|                34.0|          null|          4.7|          7.4|            75.5|         42.7|           71082|\n",
      "|     null|   Dale City|        VA|      33.4|        50.4|          49.6|             8.5|                31.2|           0.8|         13.0|         25.3|            33.4|         48.5|           71399|\n",
      "+---------+------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- percent_male: double (nullable = true)\n",
      " |-- percent_female: double (nullable = true)\n",
      " |-- percent_veterans: double (nullable = true)\n",
      " |-- percent_foreign_born: double (nullable = true)\n",
      " |-- percent_native: double (nullable = true)\n",
      " |-- percent_asian: double (nullable = true)\n",
      " |-- percent_black: double (nullable = true)\n",
      " |-- percent_hispanic: double (nullable = true)\n",
      " |-- percent_white: double (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial total count before cleaning.\n",
    "print(demographics_df.count())\n",
    "\n",
    "# Drop duplicates.\n",
    "demographics_df = demographics_df.drop_duplicates()\n",
    "\n",
    "# Group by race\n",
    "staging_demographics_df = demographics_df.groupBy(\"City\", \"State\", \"Median Age\", \"Male Population\",\n",
    "                                        \"Female Population\",\"Total Population\", \"Number of Veterans\", \n",
    "                                        \"Foreign-born\", \"Average Household Size\", \"State Code\").pivot(\"Race\").sum(\"Count\")\n",
    "\n",
    "# Normalize population by total.\n",
    "staging_demographics_df = staging_demographics_df.withColumn(\"percent_male\", (staging_demographics_df['Male Population'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_female\", (staging_demographics_df['Female Population'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_veterans\", (staging_demographics_df['Number of Veterans'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_foreign_born\", (staging_demographics_df['Foreign-born'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_native\", (staging_demographics_df['American Indian and Alaska Native'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_asian\", (staging_demographics_df['Asian'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_black\", (staging_demographics_df['Black or African-American'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_hispanic\", (staging_demographics_df['Hispanic or Latino'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"percent_white\", (staging_demographics_df['White'] / staging_demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_name_to_code(staging_demographics_df['City']))\n",
    "\n",
    "# Select specific columns.\n",
    "staging_demographics_df = staging_demographics_df.select(col(\"city_code\"),\n",
    "                                                         col(\"City\").alias(\"city_name\"),\n",
    "                                                         col(\"State Code\").alias(\"state_code\"), \n",
    "                                                         col(\"Median Age\").alias(\"median_age\"),\n",
    "                                                         round(col(\"percent_male\"), 1).alias(\"percent_male\"),\n",
    "                                                         round(col(\"percent_female\"), 1).alias(\"percent_female\"),\n",
    "                                                         round(col(\"percent_veterans\"), 1).alias(\"percent_veterans\"),\n",
    "                                                         round(col(\"percent_foreign_born\"), 1).alias(\"percent_foreign_born\"),\n",
    "                                                         round(col(\"percent_native\"), 1).alias(\"percent_native\"),\n",
    "                                                         round(col(\"percent_asian\"), 1).alias(\"percent_asian\"),\n",
    "                                                         round(col(\"percent_black\"), 1).alias(\"percent_black\"),\n",
    "                                                         round(col(\"percent_hispanic\"), 1).alias(\"percent_hispanic\"),\n",
    "                                                         round(col(\"percent_white\"), 1).alias(\"percent_white\"),\n",
    "                                                         col(\"Total Population\").alias(\"total_population\")\n",
    "                                                        )\n",
    "\n",
    "# Drop NaN for select columns. \n",
    "staging_demographics_df = staging_demographics_df.dropna(how=\"any\", subset=[\"city_name\", \"state_code\", \"total_population\"])\n",
    "\n",
    "# Final number of rows and schema.\n",
    "print(staging_demographics_df.count())\n",
    "staging_demographics_df.show(5)\n",
    "staging_demographics_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "##### A star schema, consisting of a central fact table of immigration transactions and surrounding dimension tables of immigrant, visa_class, transport_mode, city_temperature, city_demographic, date, is selected for optimum queries on immigration analyses.\n",
    "\n",
    "![image info](./data_model.png)\n",
    "\n",
    "##### Dimensional tables\n",
    "* immigrant - contains immigrant personal information, including age, gender, country of birth, etc.\n",
    "* visa_class - contains 3 visa classes, business, pleasure or student.\n",
    "* transport_mode - defined as air, land, sea, or other.\n",
    "* city_temperature - contains the average temperature per month and year.\n",
    "* city_demographic - contains population demographics - percentage of each gender, race, veteran, foreign born.\n",
    "* date - year, month, day, week of year, day of week.\n",
    "\n",
    "##### Fact table\n",
    "* immigration - contain information related to arrival of visitor or immigrant to U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### staging_i94\n",
    "- immigrant_id\n",
    "- arrival_date\n",
    "- city_code\n",
    "- city_name\n",
    "- state_code\n",
    "- age\n",
    "- gender\n",
    "- country_code_birth\n",
    "- country_name_birth\n",
    "- country_code_residence\n",
    "- country_name_residence\n",
    "- transport_mode\n",
    "- visa_class\n",
    "- visa_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### staging_temperature\n",
    "- year\n",
    "- month\n",
    "- city_code\n",
    "- city_name\n",
    "- average_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### staging_demographics\n",
    "- city_code\n",
    "- city_name\n",
    "- state_code\n",
    "- median_age\n",
    "- percent_male\n",
    "- percent_female\n",
    "- percent_veterans\n",
    "- percent_foreign_born\n",
    "- percent_native\n",
    "- percent_asian\n",
    "- percent_black\n",
    "- percent_hispanic\n",
    "- percent_white\n",
    "- total_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### immigrant_dim\n",
    "- immigrant_id INT\n",
    "- age INT\n",
    "- gender VARCHAR\n",
    "- country_code_birth INT\n",
    "- country_name_birth VARCHAR\n",
    "- country_code_residence INT\n",
    "- country_name_residence VARCHAR\n",
    "- visa_code VARCHAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### visa_class_dim\n",
    "- visa_id INT\n",
    "- visa_class VARCHAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### transport_mode_dim\n",
    "- mode_id INT\n",
    "- mode VARCHAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### city_temperature_dim\n",
    "- city_code VARCHAR\n",
    "- city_name VARCHAR\n",
    "- year INT\n",
    "- month INT\n",
    "- average_temperature FLOAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### city_demographics_dim\n",
    "- city_code VARCHAR\n",
    "- city_name VARCHAR\n",
    "- state_code VARCHAR\n",
    "- median_age FLOAT\n",
    "- percent_male FLOAT\n",
    "- percent_female FLOAT\n",
    "- percent_veterans FLOAT\n",
    "- percent_foreign_born FLOAT\n",
    "- percent_native FLOAT\n",
    "- percent_asian FLOAT\n",
    "- percent_black FLOAT\n",
    "- percent_hispanic FLOAT\n",
    "- percent_white FLOAT\n",
    "- total_population INT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### date_dim\n",
    "- arrival_date VARCHAR\n",
    "- year INT\n",
    "- month INT\n",
    "- day INT\n",
    "- week_of_year INT\n",
    "- day_of_week INT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### immigration_fact\n",
    "- immigrant_id INT\n",
    "- arrival_date VARCHAR\n",
    "- city_code VARCHAR\n",
    "- city_name VARCHAR\n",
    "- state_code VARCHAR\n",
    "- visa_class INT\n",
    "- transport_mode INT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Load all datasets.\n",
    "2. Eliminate any neccessary missing data, perform data transformations, select only pertinent data.\n",
    "3. Load to staging tables - staging_i94, staging_temperature, staging_demographics.\n",
    "4. Create the dimensional tables - immigrant_dim, visa_class_dim, transport_mode_dim, city_temperature_dim, city_demographics_dim, date_dim.\n",
    "5. Create fact table - immigration_fact.\n",
    "6. Run quality checks on each of the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2943669\n",
      "+------------+---+------+------------------+------------------+----------------------+----------------------+---------+\n",
      "|immigrant_id|age|gender|country_code_birth|country_name_birth|country_code_residence|country_name_residence|visa_code|\n",
      "+------------+---+------+------------------+------------------+----------------------+----------------------+---------+\n",
      "|     3832338| 42|     M|               108|           DENMARK|                   108|               DENMARK|       WT|\n",
      "|     1159817| 17|     F|               111|            FRANCE|                   111|                FRANCE|       WT|\n",
      "|     1350305| 36|     M|               111|            FRANCE|                   111|                FRANCE|       WT|\n",
      "|     2881970| 43|     F|               111|            FRANCE|                   111|                FRANCE|       WT|\n",
      "|     4480315| 25|     M|               111|            FRANCE|                   111|                FRANCE|       WT|\n",
      "+------------+---+------+------------------+------------------+----------------------+----------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - immigrant_dim.\n",
    "immigrant_dim = staging_i94_df.select(\"immigrant_id\",\n",
    "                                      \"age\",\n",
    "                                      \"gender\",\n",
    "                                      \"country_code_birth\",\n",
    "                                      \"country_name_birth\",\n",
    "                                      \"country_code_residence\",\n",
    "                                      \"country_name_residence\",\n",
    "                                      \"visa_code\"\n",
    "                                     ).drop_duplicates()\n",
    "\n",
    "# Save to parquet.\n",
    "immigrant_dim.write.parquet(os.path.join(output_data, 'immigrant.parquet'), 'overwrite')\n",
    "print(immigrant_dim.count())\n",
    "immigrant_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "+-------+----------+\n",
      "|visa_id|visa_class|\n",
      "+-------+----------+\n",
      "|      1|  Business|\n",
      "|      2|  Pleasure|\n",
      "|      3|   Student|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - visa_class_dim.\n",
    "# Based on https://stackoverflow.com/questions/61339594/how-to-convert-a-dictionary-to-dataframe-in-pyspark.\n",
    "visa_class_dim = spark.createDataFrame(visa_class_dict.items(),\n",
    "                                      schema=StructType(fields=[\n",
    "                                          StructField(\"visa_id\", StringType()),\n",
    "                                          StructField(\"visa_class\", StringType())\n",
    "                                      ]))\n",
    "\n",
    "# Save to parquet.\n",
    "visa_class_dim.write.parquet(os.path.join(output_data, 'visa_class.parquet'), 'overwrite')\n",
    "print(visa_class_dim.count())\n",
    "visa_class_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "+-------+--------------+\n",
      "|mode_id|transport_mode|\n",
      "+-------+--------------+\n",
      "|      1|           Air|\n",
      "|      2|           Sea|\n",
      "|      3|          Land|\n",
      "|      9|  Not reported|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - transport_mode_dim.\n",
    "# Based on https://stackoverflow.com/questions/61339594/how-to-convert-a-dictionary-to-dataframe-in-pyspark.\n",
    "transport_mode_dim = spark.createDataFrame(transport_mode_dict.items(),\n",
    "                                          schema=StructType(fields=[\n",
    "                                          StructField(\"mode_id\", StringType()),\n",
    "                                          StructField(\"transport_mode\", StringType())\n",
    "                                      ]))\n",
    "\n",
    "# Save to parquet.\n",
    "transport_mode_dim.write.parquet(os.path.join(output_data, 'transport_mode.parquet'), 'overwrite')\n",
    "print(transport_mode_dim.count())\n",
    "transport_mode_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312\n",
      "+---------+-----------+----+-----+-------------------+\n",
      "|city_code|  city_name|year|month|average_temperature|\n",
      "+---------+-----------+----+-----+-------------------+\n",
      "|     null|Clarksville|2013|    1|                4.8|\n",
      "|     null|     Dayton|2013|    8|               22.4|\n",
      "|     null|     Durham|2013|    3|                6.6|\n",
      "|     null|     Edison|2013|    7|               24.7|\n",
      "|     null| Fort Wayne|2013|    3|                0.6|\n",
      "+---------+-----------+----+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - city_temperature_dim.\n",
    "city_temperature_dim = staging_temperature_df.select(\"city_code\", \"city_name\", \"year\", \"month\", \"average_temperature\").drop_duplicates()\n",
    "\n",
    "# Save to parquet.\n",
    "city_temperature_dim.write.parquet(os.path.join(output_data, 'city_temperature.parquet'), 'overwrite')\n",
    "print(city_temperature_dim.count())\n",
    "city_temperature_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596\n",
      "+---------+-------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "|city_code|    city_name|state_code|median_age|percent_male|percent_female|percent_veterans|percent_foreign_born|percent_native|percent_asian|percent_black|percent_hispanic|percent_white|total_population|\n",
      "+---------+-------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "|      RCM|     Richmond|        CA|      35.3|        48.0|          52.0|             3.3|                38.5|           2.1|         18.3|         25.0|            41.1|         32.9|          109715|\n",
      "|     null|      Madison|        WI|      30.7|        49.2|          50.8|             3.9|                12.1|           0.9|          9.6|          8.2|             7.9|         82.1|          248956|\n",
      "|     null|  East Orange|        NJ|      35.5|        46.2|          53.8|             2.9|                23.3|           0.8|          1.0|         89.1|             9.8|          4.9|           64962|\n",
      "|     null|The Woodlands|        TX|      38.8|        47.1|          52.9|             7.0|                17.8|           2.0|          7.4|          5.4|            16.4|         89.1|          119144|\n",
      "|     null|    Cambridge|        MA|      31.5|        50.2|          49.8|             2.3|                25.1|           0.8|         16.7|         10.8|             8.5|         73.0|          110402|\n",
      "+---------+-------------+----------+----------+------------+--------------+----------------+--------------------+--------------+-------------+-------------+----------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - city_demographics_dim.\n",
    "city_demographic_dim = staging_demographics_df.select(\"city_code\", \n",
    "                                                      \"city_name\", \n",
    "                                                      \"state_code\", \n",
    "                                                      \"median_age\", \n",
    "                                                      \"percent_male\", \n",
    "                                                      \"percent_female\", \n",
    "                                                      \"percent_veterans\",\n",
    "                                                      \"percent_foreign_born\",\n",
    "                                                      \"percent_native\",\n",
    "                                                      \"percent_asian\",\n",
    "                                                      \"percent_black\",\n",
    "                                                      \"percent_hispanic\",\n",
    "                                                      \"percent_white\",\n",
    "                                                      \"total_population\"\n",
    "                                                     ).drop_duplicates()\n",
    "\n",
    "# Save to parquet.\n",
    "city_demographic_dim.write.parquet(os.path.join(output_data, 'city_demographic.parquet'), 'overwrite')\n",
    "print(city_demographic_dim.count())\n",
    "city_demographic_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "+-------------------+----+-----+-----------+---+\n",
      "|       arrival_date|year|month|week_of_day|day|\n",
      "+-------------------+----+-----+-----------+---+\n",
      "|2016-04-16T00:00:00|2016|    4|         15| 16|\n",
      "|2016-04-14T00:00:00|2016|    4|         15| 14|\n",
      "|2016-04-18T00:00:00|2016|    4|         16| 18|\n",
      "|2016-04-10T00:00:00|2016|    4|         14| 10|\n",
      "|2016-04-26T00:00:00|2016|    4|         17| 26|\n",
      "+-------------------+----+-----+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional table - date_dim.\n",
    "date_time_dim = staging_i94_df.select(\"arrival_date\").drop_duplicates()\n",
    "date_time_dim = date_time_dim.withColumn('year', year('arrival_date')) \\\n",
    "    .withColumn(\"month\", month(\"arrival_date\")) \\\n",
    "    .withColumn(\"week_of_day\", weekofyear(\"arrival_date\")) \\\n",
    "    .withColumn(\"day\", dayofmonth(\"arrival_date\"))\n",
    "\n",
    "# Save to parquet.\n",
    "date_time_dim.write.parquet(os.path.join(output_data, 'date_time.parquet'), 'overwrite')\n",
    "print(date_time_dim.count())\n",
    "date_time_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2943669\n",
      "+------------+-------------------+---------+----------------+----------+----------+--------------+\n",
      "|immigrant_id|       arrival_date|city_code|       city_name|state_code|visa_class|transport_mode|\n",
      "+------------+-------------------+---------+----------------+----------+----------+--------------+\n",
      "|     3302204|2016-04-18T00:00:00|      LOS|     LOS ANGELES|        CA|         2|             1|\n",
      "|     4853697|2016-04-26T00:00:00|      NYC|        NEW YORK|        DC|         2|             1|\n",
      "|        6954|2016-04-01T00:00:00|      NYC|        NEW YORK|        NY|         2|             1|\n",
      "|      631588|2016-04-04T00:00:00|      NEW|NEWARK/TETERBORO|        NY|         2|             1|\n",
      "|     1783463|2016-04-10T00:00:00|      NYC|        NEW YORK|        NY|         2|             1|\n",
      "+------------+-------------------+---------+----------------+----------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the fact table - immigration_fact.\n",
    "immigration_fact = staging_i94_df.select(\"immigrant_id\", \"arrival_date\", \"city_code\", \"city_name\", \"state_code\", \"visa_class\", \"transport_mode\").drop_duplicates()\n",
    "\n",
    "# Save to parquet.\n",
    "immigration_fact.write.parquet(os.path.join(output_data, 'immigration.parquet'), 'overwrite')\n",
    "print(immigration_fact.count())\n",
    "immigration_fact.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "##### Data quality checks include counting the number of rows in each tables to ensure non-empty tables, as well as on the saved parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed, number of rows in immigrant table is 2943669\n",
      "Data quality check passed, number of rows in visa_class table is 3\n",
      "Data quality check passed, number of rows in transport_mode table is 4\n",
      "Data quality check passed, number of rows in city_temperature table is 2312\n",
      "Data quality check passed, number of rows in city_demographic table is 596\n",
      "Data quality check passed, number of rows in date_time table is 30\n",
      "Data quality check passed, number of rows in immigration table is 2943669\n"
     ]
    }
   ],
   "source": [
    "# Data quality to ensure number of rows in each table is at least 1.\n",
    "dict_tables = {\n",
    "    'immigrant': immigrant_dim, \n",
    "    'visa_class': visa_class_dim, \n",
    "    'transport_mode': transport_mode_dim, \n",
    "    'city_temperature': city_temperature_dim, \n",
    "    'city_demographic': city_demographic_dim, \n",
    "    'date_time': date_time_dim, \n",
    "    'immigration': immigration_fact\n",
    "}\n",
    "\n",
    "def number_rows_in_table(key, table):  \n",
    "    number_rows = table.count()\n",
    "    if number_rows > 0:\n",
    "        print(\"Data quality check passed, number of rows in \" + key + \" table is \" + str(number_rows))\n",
    "    else:\n",
    "        print(\"Data quality check failed, \" + str(number_rows) + \"number of rows in \" + key + \" table.\")\n",
    "\n",
    "for key, table in dict_tables.items():\n",
    "    number_rows_in_table(key, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed, number of rows in immigrant table is 2943669\n",
      "Data quality check passed, number of rows in visa_class table is 3\n",
      "Data quality check passed, number of rows in transport_mode table is 4\n",
      "Data quality check passed, number of rows in city_temperature table is 2312\n",
      "Data quality check passed, number of rows in city_demographic table is 596\n",
      "Data quality check passed, number of rows in date_time table is 30\n",
      "Data quality check passed, number of rows in immigration table is 2943669\n"
     ]
    }
   ],
   "source": [
    "# Check to test if saved parquets are readable\n",
    "for key in dict_tables.keys():\n",
    "    filename = os.path.join(output_data, key + '.parquet')\n",
    "    df = spark.read.parquet(filename)\n",
    "    number_rows_in_table(key, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Immigration Fact Table\n",
    "###### immigration_fact\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "immigrant_id|Unique record ID\n",
    "arrival_date|Arrival Date in the USA\n",
    "city_code|Code for port of admission\n",
    "city_name|Port of admission\n",
    "state_code|USA State of arrival\n",
    "visa_class|Visa codes collapsed into three categories\n",
    "transport_mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Immigrant Dimension Table \n",
    "###### immigrant_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "immigrant_id|Unique record ID\n",
    "age|Age of Respondent in Years\n",
    "gender|Non-immigrant sex\n",
    "country_code_birth|3 digit code for immigrant country of birth\n",
    "country_name_birth|immigrant country of birth\n",
    "country_code_residence|3 digit code for immigrant country of residence\n",
    "country_name_residenceh|immigrant country of residence\n",
    "visa_code|Code of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Visa Class Dimension Table \n",
    "###### visa_class_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "visa_id|Visa class code\n",
    "visa_class|Class of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Transport Mode Dimension Table \n",
    "###### transport_mode_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "mode_id|Transport mode code\n",
    "Transport mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### City Temperature Dimension Table \n",
    "###### city_temperature_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "city_code|City code\n",
    "city_name|City name\n",
    "year|Year\n",
    "month|Month\n",
    "average_temperature|Global average land temperature in celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### City Demographic Dimension Table \n",
    "###### city_demographic_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "city_code|City code\n",
    "city_name|City name\n",
    "state_code|U.S. State\n",
    "median_age|Median age\n",
    "percent_male|Percentage male population\n",
    "percent_female|Percentage female population\n",
    "percent_veterans|Percentage veterans\n",
    "percent_foreign_born|Percentage foreign born residents\n",
    "percent_native|Percentage American Indian and Alaska Native population\n",
    "percent_asian|Percentage Asian population\n",
    "percent_black|Percentage Black population\n",
    "percent_hispanic|Percentage Hispanic or Latino population\n",
    "percent_white|Percentage White population\n",
    "Total Population|Total population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Date Time Dimension Table \n",
    "###### date_time_dim\n",
    "\n",
    "**Feature**|**Description**\n",
    ":-----:|:-----:\n",
    "arrival_date|Arrival date\n",
    "year|Year\n",
    "month|Month\n",
    "week_of_day|Week of day\n",
    "day|Day of month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Spark was selected this project due to:\n",
    "    * able to read very large amounts of data.\n",
    "    * can read many different file formats - csv, parquet, sas, etc.\n",
    "\n",
    "\n",
    "* How often the data should be updated and why.\n",
    "    * Currently I94 data is from April 2016, which can be updated monthly due to the high volume of visitors and immigrants. \n",
    "    * Currently city temperatures data are from 2013, which can be updated every 5 years due to larger temperature changes now as a result of climate change.\n",
    "    * Currently city demographics data are from 2015, which can be updated every 10 years after analysis by US Census Bureau.\n",
    "\n",
    "\n",
    "* Scenarios:\n",
    "    * What if the data was increased by 100x,\n",
    "        * Spark was initially selected for its ability to handle large data, and can handle the increase volume.\n",
    "        * Scale up EMR in AWS with more nodes can be added, with larger capacities.\n",
    "    * What if the data populates a dashboard that must be updated on a daily basis by 7am every day,\n",
    "        * Use Airflow to schedule data pipeline, monitor the DAG in the Airflow UI to spot any issues.\n",
    "    * What if the database needed to be accessed by 100+ people.\n",
    "        * Scale up RedShift in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
